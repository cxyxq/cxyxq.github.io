### **📌 深度学习系统化学习大纲（由浅入深）**  
🧠 **目标**：从基础概念到高级应用，全面掌握深度学习！  

---

## **🔹 第一部分：深度学习基础**
#### **1. 什么是深度学习？**
   - 深度学习 vs 机器学习
   - 神经网络为什么有效？
   - 经典应用场景（计算机视觉、自然语言处理、强化学习等）

#### **2. 神经元与感知机**
   - **生物神经元 vs 人工神经元**
   - 神经元的计算公式（线性变换 + 激活函数）
   - 感知机模型（Perceptron）
   - 感知机学习算法（权重更新规则）

#### **3. 多层神经网络（MLP）**
   - 前馈神经网络（Feedforward Neural Network, FNN）
   - 神经网络的层（输入层、隐藏层、输出层）
   - 计算过程（线性变换 + 非线性变换）
   - 权重和偏置的作用
   - 激活函数（ReLU、Sigmoid、Tanh）

#### **4. 反向传播（Backpropagation）**
   - **损失函数（Loss Function）**
     - 均方误差（MSE） vs 交叉熵损失（Cross-Entropy）
   - **梯度下降（Gradient Descent）**
     - SGD、Momentum、Adam
   - **链式法则**
     - 反向传播如何调整权重？
     - 计算梯度 & 权重更新

---

## **🔹 第二部分：深度学习框架**
#### **5. 深度学习工具**
   - PyTorch vs TensorFlow：如何选择？
   - 神经网络的搭建 & 训练流程
   - 训练、验证、测试集的划分

#### **6. 训练神经网络**
   - 过拟合与欠拟合
   - 数据增强与正则化（Dropout, BatchNorm）
   - 迁移学习（Transfer Learning）

---

## **🔹 第三部分：计算机视觉（CV）**
#### **7. 卷积神经网络（CNN）**
   - 为什么需要 CNN？
   - 卷积层（Convolution）和池化层（Pooling）
   - 经典 CNN 结构（LeNet、AlexNet、VGG、ResNet）
   - 目标检测（YOLO, Faster R-CNN）

---

## **🔹 第四部分：自然语言处理（NLP）**
#### **8. 循环神经网络（RNN & LSTM）**
   - 为什么需要 RNN？
   - RNN 的前向传播与梯度消失问题
   - LSTM、GRU 解决方案
   - 序列到序列（Seq2Seq）

#### **9. Transformer & 预训练模型**
   - 传统 RNN 的局限性
   - Transformer 的核心结构（Self-Attention, Multi-Head Attention）
   - BERT、GPT、T5 等大模型

---

## **🔹 第五部分：高级深度学习**
#### **10. 生成对抗网络（GANs）**
   - 生成器 vs 判别器
   - DCGAN, StyleGAN, Diffusion Models
   - 生成模型的应用（AI 绘画、数据增强）

#### **11. 自监督学习**
   - 为什么需要自监督学习？
   - 典型方法：SimCLR、MoCo
   - 预训练模型如何迁移学习？

#### **12. 深度强化学习（DRL）**
   - 强化学习 vs 监督学习
   - DQN, PPO, A3C
   - AlphaGo 训练原理

---

### **📌 学习路线总结**
✅ **第一阶段**：掌握神经网络的核心原理（神经元、前馈网络、反向传播）  
✅ **第二阶段**：熟练使用深度学习框架（PyTorch / TensorFlow）  
✅ **第三阶段**：深入计算机视觉（CNN）、自然语言处理（RNN & Transformer）  
✅ **第四阶段**：学习高级深度学习技术（GANs、自监督学习、强化学习）  

🚀 **你可以选择从基础开始，或者直接跳到感兴趣的应用！**